{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Group invariant ML using fundamental domain projections\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we use the approach from *B. Aslan, D. Platt, D. Sheard: “Group invariant machine learning by fundamental domain projections”* for group invariant machine learning. We apply this to the dataset from *P.S. Green, T. Hubsch and C. A. Lutken: “All Hodge Numbers of All Complete Intersection Calabi-Yau Manifolds”*. Namely, we learn learn the first Hodge numbers. Random row and column transformations were applied to input matrices.\n",
    "\n",
    "## Description of the group invariant ML architecture architecture\n",
    "\n",
    "We explain the approach for functions which take a matrix as their input and output a number.\n",
    "We say that a vector `v` is lexicographically bigger than a vector `w` if, read from front to end, the first entry where the two vectors disagree is bigger in `v` than in `w`.\n",
    "For example:\n",
    "\n",
    "```\n",
    "(1, 2, 0, -1) > (1, 1, 3, 3)\n",
    "(0.52, 1, 2)  > (0.5, -1, 3)\n",
    "```\n",
    "\n",
    "Let `F` be the map that applies row and column permutations to a given matrix to make it lexicographically as big as possible if read line by line.\n",
    "For example:\n",
    "\n",
    "```\n",
    "   0  0  0    3  1  0\n",
    "F: 0  1  3 -> 1  1  2\n",
    "   2  1  1    0  0  0\n",
    "\n",
    "because: (3, 1, 0, 1, 1, 2, 0, 0, 0) > (0, 0, 0, 0, 1, 3, 2, 1, 1)\n",
    "```\n",
    "\n",
    "The fantastic thing is: no matter how you permute rows and columns of an input matrix, the output of `F` will be the same.\n",
    "That means if you apply `F` first, followed by any machine learning algorithm, it becomes group invariant.\n",
    "\n",
    "This is easy to implement:\n",
    "instead of making `F` part of the machine learning model, you can just apply `F` to every data point (training and test data), and then use ML as usual on it.\n",
    "This works for every ML model: neural networks, SVMs, random forests...\n",
    "\n",
    "The problem is that `F` is hard to compute.\n",
    "(It has complexity greater than the graph isomorphism problem, which may be NP-hard.)\n",
    "So, practically, we just apply some random permutations to an input matrix until it doesn't get lexicographically bigger anymore.\n",
    "That means we are not guaranteed to find the global maximum, but in practice that's still okay.\n"
   ],
   "metadata": {
    "id": "rtXRqDtW0FA7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "id": "1MI1zyBJ3Qcs"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg-DpQTSV0uO",
    "outputId": "605f96f5-959b-49c6-c7b7-4fbfc0defb5d",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:25:14.721437Z",
     "start_time": "2024-11-23T20:25:14.684006Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "X = np.load('data/matrices_permuted.npy')\n",
    "y = np.load('data/hodge_numbers.npy')[:,0]"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Applying the pre-processing `F`"
   ],
   "metadata": {
    "id": "joEBppmQ3TGC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Pre-processing\n",
    "def swap_rows(M, i, j):\n",
    "  '''Swaps the i-th and j-th rows of the input matrix M.'''\n",
    "  v = M.copy()\n",
    "  v[[i,j]] = v[[j,i]]\n",
    "  return v\n",
    "\n",
    "def swap_cols(M, i, j):\n",
    "  '''Swaps the i-th and j-th columns of the input matrix M.'''\n",
    "  v = M.copy()\n",
    "  v[:, [i, j]] = v[:, [j, i]]\n",
    "  return v\n",
    "\n",
    "def greater(A, B):\n",
    "  '''Returns True if A is lexicographically greater than B.'''\n",
    "  A = np.reshape(A,-1)\n",
    "  B = np.reshape(B,-1)\n",
    "  try:\n",
    "    idx = np.where( (A>B) != (A<B) )[0][0]\n",
    "  except IndexError as e:\n",
    "    return False\n",
    "\n",
    "  if A[idx] > B[idx]:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def maximise_matrix(M):\n",
    "  '''Applies column and row transpositions to make the input matrix M\n",
    "  lexicographically as big as possible.'''\n",
    "  rows = M.shape[0]\n",
    "  cols = M.shape[1]\n",
    "\n",
    "  max_found = False\n",
    "\n",
    "  while not max_found:\n",
    "    max_found = True\n",
    "    for rowpair in itertools.combinations(range(rows), 2):\n",
    "      if greater(swap_rows(M, rowpair[0], rowpair[1]), M):\n",
    "        M = swap_rows(M, rowpair[0], rowpair[1])\n",
    "        max_found = False\n",
    "    for colpair in itertools.combinations(range(cols), 2):\n",
    "      if greater(swap_cols(M, colpair[0], colpair[1]), M):\n",
    "        M = swap_cols(M, colpair[0], colpair[1])\n",
    "        max_found = False\n",
    "  return M\n",
    "\n",
    "X_preprocessed = []\n",
    "for mat in tqdm(X):\n",
    "  X_preprocessed += [maximise_matrix(mat)]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlpyU4wqkHul",
    "outputId": "ca91e198-af23-49b2-a282-29f7786bec7e",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:25:32.977972Z",
     "start_time": "2024-11-23T20:25:14.723959Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7890/7890 [00:18<00:00, 432.63it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "X.reshape(-1,180)\n",
    "X_preprocessed = np.array(X_preprocessed).reshape(-1,180)"
   ],
   "metadata": {
    "id": "gdFd64kHkfxG",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:25:33.045624Z",
     "start_time": "2024-11-23T20:25:33.040957Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the neural network"
   ],
   "metadata": {
    "id": "GhoxAND4335M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X = torch.tensor(X_preprocessed, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "# define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(180, 128)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "def check_acc(model, X, y):\n",
    "  '''Prints the accuracy of the model for input data X and target values y.'''\n",
    "  y_pred = model(X)\n",
    "  accuracy = (y_pred.round() == y).float().mean()\n",
    "  print(f\"Accuracy {accuracy}\")\n",
    "\n",
    "model = MLP()\n",
    "print(model)\n",
    "\n",
    "# train the model\n",
    "loss_fn   = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f'epoch: {epoch}')\n",
    "    check_acc(model, X, y)\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "check_acc(model, X, y)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cOujBOeZPx0",
    "outputId": "789cecea-f9ad-4fa7-e2da-63e19806f68e",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:25:43.838292Z",
     "start_time": "2024-11-23T20:25:33.051840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden1): Linear(in_features=180, out_features=128, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "epoch: 0\n",
      "Accuracy 0.002788339741528034\n",
      "epoch: 1\n",
      "Accuracy 0.051330797374248505\n",
      "epoch: 2\n",
      "Accuracy 0.04676806181669235\n",
      "epoch: 3\n",
      "Accuracy 0.034220531582832336\n",
      "epoch: 4\n",
      "Accuracy 0.04740177467465401\n",
      "epoch: 5\n",
      "Accuracy 0.04816222935914993\n",
      "epoch: 6\n",
      "Accuracy 0.049936629831790924\n",
      "epoch: 7\n",
      "Accuracy 0.05095057189464569\n",
      "epoch: 8\n",
      "Accuracy 0.05386565253138542\n",
      "epoch: 9\n",
      "Accuracy 0.05766793340444565\n",
      "epoch: 10\n",
      "Accuracy 0.06248415634036064\n",
      "epoch: 11\n",
      "Accuracy 0.0661596953868866\n",
      "epoch: 12\n",
      "Accuracy 0.05234473943710327\n",
      "epoch: 13\n",
      "Accuracy 0.07338403165340424\n",
      "epoch: 14\n",
      "Accuracy 0.07148288935422897\n",
      "epoch: 15\n",
      "Accuracy 0.10494296252727509\n",
      "epoch: 16\n",
      "Accuracy 0.11863117665052414\n",
      "epoch: 17\n",
      "Accuracy 0.13307984173297882\n",
      "epoch: 18\n",
      "Accuracy 0.15297845005989075\n",
      "epoch: 19\n",
      "Accuracy 0.16070975363254547\n",
      "epoch: 20\n",
      "Accuracy 0.17959442734718323\n",
      "epoch: 21\n",
      "Accuracy 0.2092522233724594\n",
      "epoch: 22\n",
      "Accuracy 0.22433459758758545\n",
      "epoch: 23\n",
      "Accuracy 0.2288973331451416\n",
      "epoch: 24\n",
      "Accuracy 0.26425856351852417\n",
      "epoch: 25\n",
      "Accuracy 0.26387831568717957\n",
      "epoch: 26\n",
      "Accuracy 0.2750316858291626\n",
      "epoch: 27\n",
      "Accuracy 0.2885931432247162\n",
      "epoch: 28\n",
      "Accuracy 0.28707224130630493\n",
      "epoch: 29\n",
      "Accuracy 0.3064638674259186\n",
      "epoch: 30\n",
      "Accuracy 0.3125475347042084\n",
      "epoch: 31\n",
      "Accuracy 0.3288973271846771\n",
      "epoch: 32\n",
      "Accuracy 0.3359949290752411\n",
      "epoch: 33\n",
      "Accuracy 0.3420785665512085\n",
      "epoch: 34\n",
      "Accuracy 0.3411913812160492\n",
      "epoch: 35\n",
      "Accuracy 0.34930291771888733\n",
      "epoch: 36\n",
      "Accuracy 0.3664131760597229\n",
      "epoch: 37\n",
      "Accuracy 0.3642585575580597\n",
      "epoch: 38\n",
      "Accuracy 0.38174906373023987\n",
      "epoch: 39\n",
      "Accuracy 0.3795944154262543\n",
      "epoch: 40\n",
      "Accuracy 0.38365018367767334\n",
      "epoch: 41\n",
      "Accuracy 0.40354880690574646\n",
      "epoch: 42\n",
      "Accuracy 0.40405577421188354\n",
      "epoch: 43\n",
      "Accuracy 0.4055766761302948\n",
      "epoch: 44\n",
      "Accuracy 0.4233206510543823\n",
      "epoch: 45\n",
      "Accuracy 0.42268693447113037\n",
      "epoch: 46\n",
      "Accuracy 0.4169835150241852\n",
      "epoch: 47\n",
      "Accuracy 0.4352344870567322\n",
      "epoch: 48\n",
      "Accuracy 0.4302915036678314\n",
      "epoch: 49\n",
      "Accuracy 0.42674270272254944\n",
      "Accuracy 0.4330798387527466\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ]
}
