{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Group invariant neural networks via restricted weights\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook we use the approach from *Jason Hartford, Devon Graham, Kevin Leyton-Brown, Siamak Ravanbakhsh: “Deep Models of Interactions Across Sets”* for group invariant machine learning. (This is a generalisation of *Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola: “Deep Sets”* and a special case of *Haggai Maron, Or Litany, Gal Chechik, Ethan Fetaya: “On Learning Sets of Symmetric Elements”*) We apply this to the dataset from *P.S. Green, T. Hubsch and C. A. Lutken: “All Hodge Numbers of All Complete Intersection Calabi-Yau Manifolds”*. Namely, we learn learn the first Hodge numbers. Random row and column transformations were applied to input matrices.\n",
    "\n",
    "## Description of the group invariant neural network architecture\n",
    "\n",
    "The approach works for functions whose inputs are matrices. Given a linear map `f` and an input matrix `M`, one can act by a permutation s on the input `M`, or on the output `M`. f is called equivariant if `f(s·M)=s·f(M)`.\n",
    "\n",
    "How many linear maps are there satisfying this property? Surprisingly, the answer is **four**. And that doesn't depend on the size of the matrix. The four linear maps are:\n",
    "\n",
    "1. Multiply every entry of M by some fixed number\n",
    "2. Take the average of every row, write it next to each other to get a matrix of the original size, and multiply the result by some fixed number\n",
    "3. Do the same but for columns\n",
    "4. Take the average of all matrix elements, repeat that number to get a matrix of the original size, and multiply it by some fixed number\n",
    "\n",
    "We can take many of these maps one after another, but also simultaneously (in “channels”) to create a neural network with many parameters. The result is an equivariant function. One gets an invariant function from this by taking a pooling operation, for example the sum over all elements.\n"
   ],
   "metadata": {
    "id": "3dMErrR3yjjd"
   },
   "id": "3dMErrR3yjjd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "id": "4lTYg5nfzCjc"
   },
   "id": "4lTYg5nfzCjc"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56741b1dfa4e8215",
    "outputId": "e4e1d49b-4c99-405d-d918-4a923d691e0b",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:24:15.791568Z",
     "start_time": "2024-11-23T20:24:15.750310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "X = np.load('data/matrices_permuted.npy')\n",
    "y = np.load('data/hodge_numbers.npy')[:,0]"
   ],
   "id": "56741b1dfa4e8215",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Definition of the neural network architecture"
   ],
   "metadata": {
    "id": "67Z469DtzLUP"
   },
   "id": "67Z469DtzLUP"
  },
  {
   "metadata": {
    "id": "3c86b042f6f7f972",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:24:17.839791Z",
     "start_time": "2024-11-23T20:24:15.795620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def equivariant_layer(inp, number_of_channels_in, number_of_channels_out):\n",
    "    # four parameters:\n",
    "    # (1) Multiply every element of the matrix by a parameter\n",
    "    # (2) Take the average of every row, which gives a 12x1 matrix. Write that 15 times next to each other to get a 12x15 matrix. Multiply the result by a parameter\n",
    "    # (3) Same for columns\n",
    "    # (4) Take the average of all matrix elements, which gives a 1x1 matrix. Repeat that number to get a 12x15 matrix. Multiply the result by a parameter\n",
    "    # inp = layers.Reshape((12, 15, number_of_channels_in))(inp)\n",
    "\n",
    "    # ---(1)---\n",
    "    out1 = layers.Conv2D(number_of_channels_out, (1,1), strides=(1, 1), padding='valid', use_bias=False, activation='relu')(inp)\n",
    "\n",
    "    # ---(2)---\n",
    "    out2 = layers.AveragePooling2D((1, 15), strides=(1, 1), padding='valid')(inp)\n",
    "    repeated2 = [out2 for _ in range(15)]\n",
    "    out2 = layers.Concatenate(axis=2)(repeated2)\n",
    "    out2 = layers.Conv2D(number_of_channels_out, (1,1), strides=(1, 1), padding='valid', use_bias=False, activation='relu')(out2)\n",
    "\n",
    "    # ---(3)---\n",
    "    out3 = layers.AveragePooling2D((12, 1), strides=(1, 1), padding='valid')(inp)\n",
    "    repeated3 = [out3 for _ in range(12)]\n",
    "    out3 = layers.Concatenate(axis=1)(repeated3)\n",
    "    out3 = layers.Conv2D(number_of_channels_out, (1,1), strides=(1, 1), padding='valid', use_bias=False, activation='relu')(out3)\n",
    "\n",
    "    # ---(4)---\n",
    "    out4 = layers.AveragePooling2D((12, 15), strides=(1, 1), padding='valid')(inp)\n",
    "    repeated4 = [out4 for _ in range(12)]\n",
    "    out4 = layers.Concatenate(axis=1)(repeated4)\n",
    "    repeated4 = [out4 for _ in range(15)]\n",
    "    out4 = layers.Concatenate(axis=2)(repeated4)\n",
    "    out4 = layers.Conv2D(number_of_channels_out, (1,1), strides=(1, 1), padding='valid', use_bias=True, activation='relu')(out4)\n",
    "\n",
    "    return layers.Add()([out1,out2,out3,out4])"
   ],
   "id": "3c86b042f6f7f972",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel/PycharmProjects/PythonProject/Invariant-ML-Intro/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "id": "4e6a7a9a4e943ab8",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:24:17.894224Z",
     "start_time": "2024-11-23T20:24:17.890261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def soft_acc(y_true, y_pred):\n",
    "    '''Given two vectors, round both of them element-wise and return the fraction of\n",
    "    elements that are equal.'''\n",
    "    y_pred = tf.cast(tf.round(y_pred), tf.float32)\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(tf.round(y_true), tf.round(y_pred)), tf.float32))\n",
    "\n",
    "def get_hartford_network(pooling='sum'):\n",
    "    '''This constructs the neural network. The architecture is:\n",
    "    3 equivariant layers, followed by pooling, followed by one hidden fully\n",
    "    connected layer.'''\n",
    "    number_of_channels = 32\n",
    "    inp = layers.Input(shape=(12,15,1))\n",
    "    inp_list = [inp for _ in range(number_of_channels)]\n",
    "    inp_duplicated = layers.Concatenate(axis=3)(inp_list)\n",
    "    e1 = equivariant_layer(inp_duplicated, number_of_channels, number_of_channels)\n",
    "    e2 = equivariant_layer(e1, number_of_channels, number_of_channels)\n",
    "    e3 = equivariant_layer(e2, number_of_channels, number_of_channels)\n",
    "\n",
    "    if pooling=='sum':\n",
    "        p1 = layers.AveragePooling2D((12, 15), strides=(1, 1), padding='valid')(e3)\n",
    "    else:\n",
    "        p1 = layers.MaxPooling2D((12, 15), strides=(1, 1), padding='valid')(e3)\n",
    "    p2 = layers.Reshape((number_of_channels,))(p1)\n",
    "    fc1 = layers.Dense(32, activation='relu')(p2)\n",
    "    out = layers.Dense(1, activation='linear')(fc1)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=optimizers.Adam(0.001),\n",
    "        metrics=[soft_acc],\n",
    "    )\n",
    "    return model"
   ],
   "id": "4e6a7a9a4e943ab8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the neural network"
   ],
   "metadata": {
    "id": "h6fD3T5TzX-S"
   },
   "id": "h6fD3T5TzX-S"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36cc4b5f8fae5985",
    "outputId": "8ef9f2ea-80e9-4c02-f2ae-474c6ce0c2e5",
    "ExecuteTime": {
     "end_time": "2024-11-23T20:24:51.664937Z",
     "start_time": "2024-11-23T20:24:17.899912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_hartford_network(X_train, y_train, X_test, y_test):\n",
    "    model = get_hartford_network()\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=4,\n",
    "        validation_data=(X_test, y_test),\n",
    "        batch_size=1\n",
    "    )\n",
    "    return history.history['val_soft_acc'][-1]\n",
    "\n",
    "\n",
    "model = get_hartford_network()\n",
    "print(f'Test Accuracy of Hartford Neural Network after one run: {train_hartford_network(X, y, X, y)}')\n"
   ],
   "id": "36cc4b5f8fae5985",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001B[1m7890/7890\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m9s\u001B[0m 1ms/step - loss: 3.4541 - soft_acc: 0.2254 - val_loss: 2.9639 - val_soft_acc: 0.4676\n",
      "Epoch 2/4\n",
      "\u001B[1m7890/7890\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 1ms/step - loss: 2.5091 - soft_acc: 0.3000 - val_loss: 2.1288 - val_soft_acc: 0.3894\n",
      "Epoch 3/4\n",
      "\u001B[1m7890/7890\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 1ms/step - loss: 2.2002 - soft_acc: 0.3222 - val_loss: 1.8726 - val_soft_acc: 0.3670\n",
      "Epoch 4/4\n",
      "\u001B[1m7890/7890\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m8s\u001B[0m 1ms/step - loss: 2.1187 - soft_acc: 0.3784 - val_loss: 2.4097 - val_soft_acc: 0.5312\n",
      "Test Accuracy of Hartford Neural Network after one run: 0.5311787128448486\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
